# üîß Feature Engineering Strategy
## ML Trading System - Technical Indicators & Feature Calculation

---

## üìã Table of Contents

1. [Current System Analysis](#current-system-analysis)
2. [Feature Engineering Requirements](#feature-engineering-requirements)
3. [Storage Strategy Options](#storage-strategy-options)
4. [Trigger Mechanism Options](#trigger-mechanism-options)
5. [Performance & Scalability Considerations](#performance--scalability-considerations)
6. [Integration Points](#integration-points)
7. [Implementation Approaches](#implementation-approaches)
8. [Risk Assessment](#risk-assessment)
9. [Recommended Approach](#recommended-approach)
10. [Future Considerations](#future-considerations)

---

## Current System Analysis

### **Existing Yahoo Data Pipeline**
```
Yahoo Collector ‚Üí PostgreSQL ‚Üí Prefect Workflows ‚Üí Dashboard
     ‚Üì               ‚Üì              ‚Üì               ‚Üì
- yfinance API   - market_data   - Hourly runs    - Real-time UI
- OHLCV data     - stock_info    - Concurrent     - Chart display
- Multiple       - Logging       - Retry logic    - Performance
  symbols        - Performance   - Monitoring     - Monitoring
```

### **Current Data Flow**
1. **Prefect Schedule**: Runs every 15 minutes during market hours
2. **Yahoo Collector**: Fetches OHLCV data for ~100 symbols
3. **Database Storage**: Inserts/updates `market_data` table
4. **Dashboard Display**: Real-time chart rendering from raw data

### **Existing Infrastructure Strengths**
- ‚úÖ Robust error handling and retry logic
- ‚úÖ Concurrent processing (5 workers)
- ‚úÖ Comprehensive logging and monitoring
- ‚úÖ Connection pooling and database optimization
- ‚úÖ Prefect workflow orchestration
- ‚úÖ Real-time dashboard integration

### **Current Limitations for Feature Engineering**
- ‚ùå No technical indicators calculated
- ‚ùå Raw OHLCV data only
- ‚ùå No feature storage mechanism
- ‚ùå No automated feature calculation triggers

---

## Feature Engineering Requirements

### **Technical Indicators Needed**
```yaml
Moving Averages:
  - Simple Moving Average (5, 10, 20, 50 periods)
  - Exponential Moving Average (12, 26 periods)

Momentum Indicators:
  - MACD (12, 26, 9)
  - RSI (14 period)
  - Rate of Change (10 period)
  - Momentum (5, 10 periods)

Volatility Indicators:
  - Bollinger Bands (20, 2)
  - Average True Range (14)
  - Historical Volatility (5d, 20d)

Volume Indicators:
  - Volume Moving Average (20)
  - Volume Ratio
  - Volume Profile

Price Action Features:
  - Daily Returns
  - Price Changes (absolute & percentage)
  - Intraday Range
  - Gap Analysis
  - Support/Resistance Levels
```

### **Feature Calculation Requirements**
- **Lookback Window**: Minimum 50-100 periods for accurate calculations
- **Update Frequency**: After each Yahoo data collection cycle
- **Calculation Speed**: Must not significantly slow down data pipeline
- **Data Quality**: Handle missing data, outliers, and data gaps
- **Historical Backfill**: Calculate features for existing historical data

---

## ‚úÖ CONFIRMED STORAGE STRATEGY

### **SELECTED: Separate Feature Table**

We have confirmed the use of Option 1 - Separate Feature Table approach:

#### **Implementation Details:**
- **Table Name**: `feature_engineered_data`
- **Relationship**: Foreign key reference to `market_data(symbol, timestamp)`
- **Schema**: 65-85+ feature columns + metadata
- **Benefits**: Clean separation, no impact on existing code, flexible feature versioning

#### **Schema Design (Confirmed):**
```sql
feature_engineered_data:
  - Primary key: (symbol, timestamp, source)
  - Foreign key: References market_data
  - Feature columns: 65-85+ technical indicators across 5 phases
  - Metadata: feature_version, created_at, updated_at
  - Indexes: symbol, timestamp, created_at
```

---

## ‚úÖ CONFIRMED TRIGGER MECHANISM

### **SELECTED: Sequential Processing**

We have confirmed the use of Option 1 - Sequential Trigger approach:

```
Yahoo Collection (10 min) ‚Üí Feature Engineering (3 sec) ‚Üí Dashboard Update
```

#### **Implementation Details:**
- **Data Consistency**: Features always based on complete latest data
- **Simple Dependencies**: Clear sequential workflow in Prefect
- **Performance Impact**: <3 seconds for 100 symbols with 5 workers
- **Benefits**: Ensures data integrity, easy monitoring and troubleshooting

---

## Performance & Scalability Considerations

### **Current System Performance**
- **Yahoo Collection**: ~5-10 minutes for 100 symbols
- **Database Writes**: ~1000-2000 records per run
- **Memory Usage**: ~500MB peak
- **CPU Usage**: ~30% during collection

### **Feature Engineering Impact**

#### **Computational Requirements:**
```
Per Symbol Calculation Time:
- Technical Indicators: ~100ms (50 periods)
- Statistical Features: ~50ms
- Database Write: ~20ms
Total per symbol: ~170ms

100 Symbols Sequential: ~17 seconds
100 Symbols Parallel (5 workers): ~3.4 seconds
```

#### **Memory Requirements:**
```
Per Symbol Memory:
- Raw Data (100 periods): ~10KB
- Calculated Features: ~15KB
- Temporary Arrays: ~20KB
Total per symbol: ~45KB

100 Symbols: ~4.5MB additional memory
```

#### **Database Impact:**
```
Additional Storage per Symbol:
- Feature Records: ~30 columns √ó 100 periods = 3000 cells
- Storage per symbol: ~50KB per 100 periods
- Daily growth: ~500KB per symbol for hourly data

100 Symbols Daily: ~50MB additional storage
Annual growth: ~18GB for features
```

### **Scalability Limits**

#### **Current Bottlenecks:**
1. **Database Connections**: Limited to 25 concurrent connections
2. **Yahoo API Rate Limits**: ~2000 requests/hour
3. **Memory Usage**: Current ~500MB peak
4. **Processing Time**: 15-minute window constraint

#### **Feature Engineering Bottlenecks:**
1. **CPU Intensive**: Technical indicator calculations
2. **Memory Usage**: Historical data for lookback windows
3. **Database Writes**: Additional feature storage
4. **Dependency Chain**: Must wait for raw data

---

## Integration Points

### **Existing Codebase Integration**

#### **Database Layer:**
- `src/data/storage/database.py` - Add feature table management
- Connection pooling already handles additional load
- Existing transaction management can be extended

#### **Prefect Workflows:**
- `src/workflows/data_pipeline/` - Add feature engineering flow
- Leverage existing concurrent task runner
- Use existing logging and monitoring infrastructure

#### **Dashboard Integration:**
- `src/dashboard/` - Add feature data endpoints
- Extend existing chart components
- Use existing caching mechanisms

#### **Configuration Management:**
- `config/` - Add feature engineering parameters
- Leverage existing YAML configuration system
- Extend deployment configuration

### **New Components Needed**

#### **Feature Engineering Module:**
- `src/data/processors/feature_engineering.py`
- Technical indicator calculations
- Data validation and cleaning
- Feature storage management

#### **Feature Prefect Flow:**
- `src/workflows/data_pipeline/feature_engineering_flow.py`
- Integration with Yahoo collection flow
- Concurrent feature calculation
- Error handling and monitoring

#### **Database Schema:**
- Feature engineering table
- Indexes for performance
- Migration scripts

---

## ‚úÖ CONFIRMED IMPLEMENTATION APPROACH

### **SELECTED: Phased Implementation Strategy**

We have confirmed a 5-phase implementation approach optimized for our specific feature set:

```
Phase 1: Foundation & Validation (3-4 days) ‚Üí 13 features
Phase 2: Core Technical Analysis (4-5 days) ‚Üí 24 features  
Phase 3: Market Microstructure (4-5 days) ‚Üí 16 features
Phase 4: Advanced Features (5-6 days) ‚Üí 13 features
Phase 5: Historical Context (4-5 days) ‚Üí 30+ features
```

#### **Key Benefits:**
- **Low Risk**: Each phase validates independently
- **Incremental Value**: Trading utility increases with each phase
- **Performance Management**: Monitor impact at each phase
- **Flexible Timeline**: Can stop at any phase with complete functionality

---

## Risk Assessment

### **Technical Risks**

#### **High Risk:**
- **Pipeline Performance**: Feature calculation could slow Yahoo collection
- **Database Load**: Additional writes may impact system performance
- **Memory Usage**: Historical data for calculations may cause OOM

#### **Medium Risk:**
- **Data Consistency**: Features may be calculated on incomplete data
- **Calculation Errors**: Technical indicator edge cases and NaN handling
- **Storage Growth**: Feature data will grow database size significantly

#### **Low Risk:**
- **Integration Complexity**: Well-defined interfaces exist
- **Monitoring**: Existing logging system can be extended
- **Configuration**: YAML-based config system is flexible

### **Mitigation Strategies**

#### **Performance Mitigation:**
- Use separate Prefect workers for feature calculation
- Implement feature calculation queuing
- Add feature calculation throttling
- Monitor and alert on performance degradation

#### **Data Quality Mitigation:**
- Validate input data before feature calculation
- Handle missing data gracefully
- Implement feature calculation retry logic
- Add data quality checks and alerts

#### **Storage Mitigation:**
- Implement feature data retention policies
- Compress older feature data
- Archive historical features to separate storage
- Monitor database growth and performance

---

## üéØ IMMEDIATE NEXT STEPS

### **PRIORITY 1: Phase 1+2 Implementation (Recommended Start)**

#### **Why Start with Phase 1+2:**
- **37 Total Features**: Complete trading foundation
- **Performance Impact**: <3 seconds for 100 symbols  
- **High Trading Value**: All essential technical indicators
- **Low Risk**: Foundation + core features with proven calculations
- **1 Week Timeline**: Quick delivery of substantial functionality

#### **Phase 1+2 Feature Summary:**
```
Phase 1: Foundation (13 features)
- Basic price features: returns, volatility ratios, price acceleration
- Time features: hour, day_of_week with cyclical encoding

Phase 2: Core Technical (24 features)  
- Moving averages: 24h, 120h, 480h periods
- Technical indicators: Bollinger Bands, MACD, ATR, Williams %R
- Volatility features: Realized volatility across multiple windows
```

### **IMMEDIATE ACTION PLAN**

#### **Week 1: Core Implementation**
```
Day 1-2: Database Schema & Feature Engineering Module
- Create feature_engineered_data table
- Implement core feature calculation functions
- Set up data validation framework

Day 3-4: Prefect Integration  
- Create feature engineering flow
- Integrate with existing Yahoo collection
- Implement error handling and logging

Day 5: Testing & Validation
- Unit tests for all feature calculations
- Compare results with notebook analysis
- Performance testing and optimization
```

#### **Success Criteria for Phase 1+2:**
- ‚úÖ 37 features calculated with >95% success rate
- ‚úÖ Features match notebook analysis with >99.9% correlation  
- ‚úÖ Performance impact <3 seconds for 100 symbols
- ‚úÖ Memory usage <15MB for 100 symbols
- ‚úÖ Zero impact on existing functionality

---

## üìã IMPLEMENTATION CHECKLIST

### **Pre-Implementation Setup**
- [ ] Review and validate notebook feature calculations
- [ ] Set up development branch for feature engineering
- [ ] Configure development database for testing
- [ ] Install required Python libraries (ta-lib, pandas-ta)

### **Phase 1+2 Implementation Tasks**

#### **Database Setup**
- [ ] Create `feature_engineered_data` table schema
- [ ] Add appropriate indexes for performance  
- [ ] Set up database migration scripts
- [ ] Test database schema with sample data

#### **Feature Engineering Module**
- [ ] Create `src/data/processors/feature_engineering.py`
- [ ] Implement Phase 1 features (basic price & time)
- [ ] Implement Phase 2 features (technical indicators)
- [ ] Add comprehensive error handling and validation
- [ ] Create unit tests for all feature calculations

#### **Prefect Integration**
- [ ] Create `feature_engineering_flow.py`
- [ ] Integrate with existing Yahoo collection workflow
- [ ] Implement parallel processing for 100 symbols
- [ ] Add monitoring and logging
- [ ] Test sequential pipeline execution

#### **Validation & Testing**
- [ ] Compare all features against notebook calculations
- [ ] Performance testing with 100 symbols
- [ ] Memory usage validation
- [ ] Integration testing with existing system
- [ ] Error handling and edge case testing

### **Future Phases (Post Phase 1+2)**
- [ ] **Phase 3**: RSI features, volume analysis, market timing (16 features)
- [ ] **Phase 4**: Advanced volatility, intraday patterns (13 features)  
- [ ] **Phase 5**: Historical context, lagged features (30+ features)
- [ ] **Dashboard Integration**: Feature visualization and controls
- [ ] **Performance Optimization**: Caching, indexing, query optimization

### **Key Dependencies & Requirements**
- [ ] **Lookback Data**: Minimum 480 hours (20 days) for full calculations
- [ ] **Python Libraries**: pandas, numpy, ta-lib, pandas-ta
- [ ] **Database**: PostgreSQL with adequate storage (~3GB annual growth)
- [ ] **Performance Target**: <3 seconds additional processing time

---

## ‚úÖ IMPLEMENTATION COMPLETE

**Current Status**: Feature engineering system successfully implemented and operational.

**Delivered Solution**: On-demand feature engineering processor with comprehensive technical indicators for all market data symbols.

**Implementation Details**: Subprocess-based processing with complete connection management for reliable, scalable feature engineering.

## üéØ FINAL IMPLEMENTATION APPROACH

### **On-Demand Feature Engineering Processor**

After extensive development and testing, we implemented a robust, subprocess-based feature engineering system that processes all market data symbols with complete technical indicators.

#### **Key Implementation Details:**

**Architecture:**
- **Subprocess Isolation**: Each symbol processed in isolated subprocess for complete connection management
- **No Prefect Dependency**: Standalone processor independent of workflow orchestration
- **Database Integration**: Direct integration with existing PostgreSQL database and connection pooling
- **Comprehensive Features**: 36 technical indicators per symbol including price, time, moving averages, volatility, and technical indicators

**Performance Characteristics:**
- **Processing Speed**: ~2.0s per symbol (optimized from initial 2.4s)
- **Success Rate**: 100% reliability across all symbols
- **Memory Management**: Automatic cleanup through subprocess isolation
- **Connection Handling**: Zero connection pool exhaustion issues
- **Scalability**: Handles 1057+ symbols efficiently

**Feature Engineering Pipeline:**
```python
# Core Features (36 indicators per symbol)
Basic Price Features (6): returns, log_returns, price ratios, acceleration
Time Features (7): hour, day_of_week with cyclical encoding  
Moving Averages (8): 24h, 120h, 480h periods with ratios
Technical Indicators (10): Bollinger Bands, MACD, ATR, Williams %R
Volatility Features (5): Realized volatility across multiple windows
```

**Database Schema:**
- **Table**: `feature_engineered_data` with 107 columns
- **Storage**: ~50KB per symbol per historical dataset
- **Indexing**: Optimized for symbol/timestamp queries
- **Relationship**: Foreign key reference to market_data table

#### **Usage:**
```bash
# Process all remaining symbols
python scripts/feature_engineering_processor.py
```

**Current Status**: System successfully processing all 1057 symbols with 100% success rate, approximately 30 minutes total processing time.

### **Development Journey & Problem Resolution**

#### **Challenges Encountered:**

**Connection Pool Exhaustion:**
- **Problem**: Initial batch processing approaches suffered from PostgreSQL connection pool exhaustion after processing 10-15 symbols
- **Root Cause**: FeatureEngineer instances not properly releasing database connections, even with explicit cleanup attempts
- **Failed Solutions**: Shared instances, connection pool cleanup, batch processing with pauses
- **Final Solution**: Subprocess isolation for each symbol processing, ensuring complete memory and connection cleanup

**Performance Optimization:**
- **Initial Performance**: 2.4s per symbol
- **Optimization Steps**: Database query optimization, feature calculation streamlining, memory management
- **Final Performance**: 2.0s per symbol (17% improvement)

**Reliability Engineering:**
- **Challenge**: Need for 100% success rate across all symbols
- **Solution**: Comprehensive error handling, subprocess timeout management, automatic cleanup
- **Result**: Zero failures across 1057 symbols processed

#### **Key Technical Decisions:**

1. **Subprocess Isolation over Shared Instances**: Complete process isolation ensures reliable connection management
2. **On-Demand over Scheduled Processing**: Standalone processor allows for flexible execution timing
3. **Direct Database Integration**: Leverages existing connection pooling without adding complexity
4. **Comprehensive Feature Set**: 36 indicators provide complete technical analysis foundation

#### **Lessons Learned:**

- **Connection Management**: Database connection pooling requires complete process isolation for reliable cleanup in complex feature engineering scenarios
- **Subprocess Benefits**: Process isolation provides superior resource management over shared instances
- **Performance vs Reliability**: Subprocess overhead (0.4s) acceptable trade-off for 100% reliability
- **Development Approach**: Iterative testing with small batches before full-scale processing crucial for identifying edge cases

---

## üìä DETAILED FEATURE SPECIFICATIONS

### **Feature Constants (From Notebook Analysis)**
```python
# Optimized for hourly trading data
SHORT_WINDOW = 24        # 1 day (24 hours)
MED_WINDOW = 120         # 5 days (120 hours)  
LONG_WINDOW = 480        # 20 days (480 hours)
VOL_WINDOWS = [12, 24, 120]  # 12h, 1d, 5d
RSI_WINDOWS = {
    'rsi_1d': 24,        # 1 day
    'rsi_3d': 72,        # 3 days
    'rsi_1w': 168,       # 1 week
    'rsi_2w': 336        # 2 weeks
}
LAG_PERIODS = [1, 2, 4, 8, 24]  # 1h, 2h, 4h, 8h, 1day
ROLLING_WINDOWS = [6, 12, 24]   # 6h, 12h, 24h
```

### **Phase 1+2 Feature Details (37 Features)**

#### **Phase 1: Foundation Features (13)**
```python
# Basic Price Features (6)
returns = close.pct_change()
log_returns = log(close / close.shift(1))
high_low_pct = (high - low) / close
open_close_pct = (close - open) / open
price_acceleration = returns.diff()
returns_sign = sign(returns)

# Time Features (7)
hour, day_of_week, is_market_open
hour_sin, hour_cos (cyclical encoding)
dow_sin, dow_cos (cyclical encoding)
```

#### **Phase 2: Core Technical Features (24)**
```python
# Moving Averages (8)
price_ma_short (24h), price_ma_med (120h), price_ma_long (480h)
price_to_ma_short, price_to_ma_med, price_to_ma_long
ma_short_to_med, ma_med_to_long

# Technical Indicators (10)  
bb_upper, bb_lower, bb_position, bb_squeeze (Bollinger Bands)
macd, macd_signal, macd_histogram, macd_normalized
atr, atr_normalized, williams_r

# Volatility Features (6)
realized_vol_short (12h), realized_vol_med (24h), realized_vol_long (120h)
returns_squared, vol_ratio_short_med, vol_ratio_med_long
```

### **Database Schema (Phase 1+2)**
```sql
CREATE TABLE feature_engineered_data (
    id SERIAL PRIMARY KEY,
    symbol VARCHAR(10) NOT NULL,
    timestamp TIMESTAMP NOT NULL,
    
    -- Reference OHLCV data  
    open NUMERIC(10,4), high NUMERIC(10,4), low NUMERIC(10,4),
    close NUMERIC(10,4), volume BIGINT,
    
    -- Phase 1: Foundation Features (13)
    returns NUMERIC(10,6), log_returns NUMERIC(10,6),
    high_low_pct NUMERIC(8,6), open_close_pct NUMERIC(8,6),
    price_acceleration NUMERIC(10,6), returns_sign SMALLINT,
    hour SMALLINT, day_of_week SMALLINT, is_market_open SMALLINT,
    hour_sin NUMERIC(8,6), hour_cos NUMERIC(8,6),
    dow_sin NUMERIC(8,6), dow_cos NUMERIC(8,6),
    
    -- Phase 2: Core Technical Features (24)
    price_ma_short NUMERIC(10,4), price_ma_med NUMERIC(10,4), price_ma_long NUMERIC(10,4),
    price_to_ma_short NUMERIC(8,6), price_to_ma_med NUMERIC(8,6), price_to_ma_long NUMERIC(8,6),
    ma_short_to_med NUMERIC(8,6), ma_med_to_long NUMERIC(8,6),
    bb_upper NUMERIC(10,4), bb_lower NUMERIC(10,4), bb_position NUMERIC(8,6), bb_squeeze NUMERIC(8,6),
    macd NUMERIC(10,6), macd_signal NUMERIC(10,6), macd_histogram NUMERIC(10,6), macd_normalized NUMERIC(10,6),
    atr NUMERIC(10,4), atr_normalized NUMERIC(8,6), williams_r NUMERIC(8,4),
    realized_vol_short NUMERIC(8,6), realized_vol_med NUMERIC(8,6), realized_vol_long NUMERIC(8,6),
    returns_squared NUMERIC(10,6), vol_ratio_short_med NUMERIC(8,6), vol_ratio_med_long NUMERIC(8,6),
    
    -- Metadata
    source VARCHAR(20) DEFAULT 'yahoo',
    feature_version VARCHAR(20) DEFAULT '1.0', 
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    
    CONSTRAINT unique_symbol_timestamp_features UNIQUE (symbol, timestamp, source)
);

-- Performance indexes
CREATE INDEX idx_features_symbol_timestamp ON feature_engineered_data(symbol, timestamp);
CREATE INDEX idx_features_recent ON feature_engineered_data(symbol, timestamp DESC) 
    WHERE timestamp >= NOW() - INTERVAL '7 days';
```